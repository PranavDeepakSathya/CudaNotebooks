{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "A producer P over a buffer list B is a set of workers P(W), a single job prod:(source, target) and holds a function \n",
    "ready signal s_p : B -> {0,1} indicating the buffers that need to be produced at the current time. \n",
    "\n",
    "it has states P.free, P.waiting, P.producing. \n",
    "\n",
    "A consumer C over that same buffer list B is also a set of workers and single job, and holds a function filled signal s_c : B->{0,1}\n",
    "indicating the buffers that are filled and ready to consumed \n",
    "\n",
    "it has states C.free, C.waiting, C.consuming. \n",
    "\n",
    "a buffer b itself, is again a set/sequence of memory objects, (maybe some contigous chunk of memory)\n",
    "\n",
    "and it has states b.empty, b.getting_produced, b.full, b.getting_consumed.  \n",
    "\n",
    "\n",
    "okay, now let P be a producer, and C a consumer and B a list of buffers \n",
    "\n",
    "lets write some basic rules \n",
    "\n",
    "1. C.state(t+1) == C.waiting if  for all b in B, b.state(t) != b.full. \n",
    "\n",
    "2. P.state(t+1) == P.waiting if  for all b in B, b.state(t) != b.empty. \n",
    "\n",
    "3. The other is of course mutual exclisivity of states, a thing cannot be in two states at once \n",
    "\n",
    "4. P.state(t+1) = P.producing if for some b in B, b.state(t) = b.empty, in which case that b goes to b.state(t+1) = b.getting_produced\n",
    "    and p.state(t) != p.producing. \n",
    "    \n",
    "5  p.state(t+1) = P.free if P.state(t) = P.producing, in which case, the one b for which b.state(t) = b.getting_produced \n",
    "  now bas b.state(t+1) = b.full. \n",
    "  \n",
    "6 C.state(t+1) = C.consuming if for some b in B, b.state(t) = b.full, in which case that b goes to b.state(t+1) = b.getting_consumed\n",
    "   and C.state(t) != c.consuming \n",
    "7 C.state(t+1) = C.free if C.state(t) = C.consuming in which case the one b for which b.state(t) = b.getting_consumed \n",
    "now has state b.state(t_1) = b.empty. \n",
    "\n",
    "\n",
    "\n",
    "The init state is (P.free, C.free, bi = bi.empty for all bi in B)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398e258",
   "metadata": {},
   "source": [
    "#### Correctness spec: \n",
    "\n",
    "we have a producer $P$ a consumer $C$ and a buffer set $B$. \n",
    "We have states \n",
    "\n",
    "$S(P) = \\{p.f,s.w,p.pr\\}$, $S(C) = \\{c.f, c.w,c.cs\\}$, $s(b) = \\{e, gp, fl, gc\\}$\n",
    "\n",
    "###### System invariants: \n",
    "\n",
    "1. Mutual exclusivity, (implied by the set theory) any object can be in exactly one state at a given time. \n",
    "2. Producer lock: at any $t$, $S(P)_t = p.pr \\iff !\\exists b \\in B: s(b)_t = gp$ \n",
    "3. Consumer lock: at any $t$  $S(C)_t = c.cs \\iff !\\exists b \\in B: s(b)_t = gc$\n",
    "\n",
    "\n",
    "##### Inital state: \n",
    "\n",
    "$(S(P)_0 = p.f, \\ S(C)_0 = p.f, \\  s(b) = e \\  \\forall b \\in B$ \n",
    "\n",
    "##### tansitions \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class producer_consumer: \n",
    "  def __init__ (self, n_resources:int, n_producers:int, n_buffers:int, prod_job_latency:int, cons_job_latency:int, n_jobs): \n",
    "    \"\"\"Here, we have n paralell resources of the same \"size\" in some sense (same number of threads say)\n",
    "    we partition those into two parts, one part of producers, the other consumers. \n",
    "    we have a number of buffers, from which we can produce into and consume from, and we have some latency per resource \n",
    "    of both production and consumption, and it is obvoious that one resrouce handles the production/consumption of one job\n",
    "    the goal is to compute consume(produce(job)) for n_jobs. \n",
    "\n",
    "    Args:\n",
    "        n_resources (int): _description_\n",
    "        n_producers (int): _description_\n",
    "        n_buffers (int): _description_\n",
    "        prod_job_latency (int): _description_\n",
    "        cons_job_latency (int): _description_\n",
    "        n_jobs (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    #we just creating as many states as there are atmost clock cycles which would just be (pl + cl + 1)*n_jobs\n",
    "    self.pl = prod_job_latency \n",
    "    self.cl - cons_job_latency\n",
    "    self.max_clocks = (self.pl + self.cl + 2)*n_jobs\n",
    "    self.n_jobs = n_jobs \n",
    "    self.n_w = n_resources\n",
    "    self.n_prod = n_producers \n",
    "    self.n_cons = self.n_w - self.n_prod\n",
    "    self.n_buff = n_buffers\n",
    "    \n",
    "    self.producers_states = np.zeros((self.n_prod, self.max_clocks)).astype(int)\n",
    "    self.consumers_states = np.zeros((self.n_cons,self.max_clocks)).astype(int)\n",
    "    self.buffers_states = np.zeros((self.n_buff,n_jobs)).astype(int)\n",
    "    \n",
    "    self.producers_latency_points = np.zeros((self.n_prod)).astype(int)\n",
    "    self.consumers_latency_points = np.zeros((self.n_cons)).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(1, self.max_clocks): \n",
    "      prev_empty_buffers = self.get_empty_buffers(self.buffers_states[i-1])\n",
    "      prev_full_buffers = self.get_filled_buffers(self.buffers_states[i-1])\n",
    "      prev_getting_produced_buffers = self.get_getting_produced_buffers(self.buffers_states[i-1])\n",
    "      prev_getting_consumed_buffers = self.get_getting_consumed_buffers(self.buffers_states[i-1])\n",
    "      prev_free_producers = self.get_free_producers(self.producers_states[i-1])\n",
    "      prev_free_consumers = self.get_free_consumers(self.consumers_states[i-1])\n",
    "      prev_waiting_producers = self.get_waiting_producers(self.producers_states[i-1])\n",
    "      prev_waiting_consumers = self.get_waiting_consumers(self.consumers_states[i-1])\n",
    "      prev_producing_producers = self.get_producing_producers(self.producers_states[i-1])\n",
    "      prev_consuming_consumers = self.get_consuming_consumers(self.consumers_states[i-1])\n",
    "      \n",
    "  # --- Buffer State Getters ---\n",
    "  # 0: empty\n",
    "  # 1: getting_produced\n",
    "  # 2: full\n",
    "  # 3: getting_consumed\n",
    "\n",
    "  def get_empty_buffers(self, buffers_state): \n",
    "    \"\"\"Finds all buffers in the 'empty' (0) state.\"\"\"\n",
    "    return np.where(buffers_state == 0)\n",
    "\n",
    "  def get_filled_buffers(self, buffers_state): \n",
    "    \"\"\"Finds all buffers in the 'full' (1) state.\"\"\"\n",
    "    return np.where(buffers_state == 2)\n",
    "\n",
    "  def get_getting_produced_buffers(self, buffers_state):\n",
    "    \"\"\"Finds all buffers in the 'getting_produced' (2) state.\"\"\"\n",
    "    return np.where(buffers_state == 1)\n",
    "\n",
    "  def get_getting_consumed_buffers(self, buffers_state):\n",
    "    \"\"\"Finds all buffers in the 'getting_consumed' (3) state.\"\"\"\n",
    "    return np.where(buffers_state == 3)\n",
    "\n",
    "  # --- Producer State Getters ---\n",
    "  # 0: free\n",
    "  # 1: waiting\n",
    "  # 2: producing\n",
    "\n",
    "  def get_free_producers(self, producers_state):\n",
    "    \"\"\"Finds all producers in the 'free' (0) state.\"\"\"\n",
    "    return np.where(producers_state == 0)\n",
    "\n",
    "  def get_waiting_producers(self, producers_state):\n",
    "    \"\"\"Finds all producers in the 'waiting' (1) state.\"\"\"\n",
    "    return np.where(producers_state == 1)\n",
    "    \n",
    "  def get_producing_producers(self, producers_state): \n",
    "    \"\"\"Finds all producers in the 'producing' (2) state.\"\"\"\n",
    "    return np.where(producers_state == 2)\n",
    "\n",
    "  # --- Consumer State Getters ---\n",
    "  # 0: free\n",
    "  # 1: waiting\n",
    "  # 2: consuming\n",
    "\n",
    "  def get_free_consumers(self, consumers_state):\n",
    "    \"\"\"Finds all consumers in the 'free' (0) state.\"\"\"\n",
    "    return np.where(consumers_state == 0)\n",
    "\n",
    "  def get_waiting_consumers(self, consumers_state):\n",
    "    \"\"\"Finds all consumers in the 'waiting' (1) state.\"\"\"\n",
    "    return np.where(consumers_state == 1)\n",
    "    \n",
    "  def get_consuming_consumers(self, consumers_state): \n",
    "    \"\"\"Finds all consumers in the 'consuming' (2) state.\"\"\"\n",
    "    return np.where(consumers_state == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f85cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "okay I guess we dont really need to maintain everything, what we will do \n",
    "is maintain a ready queue and wait queue as well as a \"processing\" counter for each producer and consumer \n",
    "and just maintain the number of empty, full, filling and consumed on buffers \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque # <-- 1. Import deque\n",
    "\n",
    "class Producer_Consumer:\n",
    "  def __init__ (self, n_resources:int, n_producers:int, n_buffers:int, prod_job_latency:int, cons_job_latency:int, n_jobs):\n",
    "    \"\"\"Here, we have n paralell resources of the same \"size\" in some sense (same number of threads say)\n",
    "    we partition those into two parts, one part of producers, the other consumers.\n",
    "    we have a number of buffers, from which we can produce into and consume from, and we have some latency per resource\n",
    "    of both production and consumption, and it is obvoious that one resrouce handles the production/consumption of one job\n",
    "    the goal is to compute consume(produce(job)) for n_jobs.\n",
    "\n",
    "    Args:\n",
    "        n_resources (int): _description_\n",
    "        n_producers (int): _description_\n",
    "        n_buffers (int): _description_\n",
    "        prod_job_latency (int): _description_\n",
    "        cons_job_latency (int): _description_\n",
    "        n_jobs (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    #we just creating as many states as there are atmost clock cycles which would just be (pl + cl + 1)*n_jobs\n",
    "    self.pl = prod_job_latency\n",
    "    self.cl = cons_job_latency # <-- 2. Fixed bug (was 'self.cl -')\n",
    "    self.max_clocks = (self.pl + self.cl + 2)*n_jobs\n",
    "    self.n_jobs = n_jobs\n",
    "    self.n_w = n_resources\n",
    "    self.n_prod = n_producers\n",
    "    self.n_cons = self.n_w - self.n_prod\n",
    "    self.n_buff = n_buffers\n",
    "\n",
    "    # --- 3. Converted lists to deques ---\n",
    "    # These are pools or queues, so deque is ideal.\n",
    "    self.free_producers = deque([i for i in range(self.n_prod)])\n",
    "    self.free_consumers = deque([i for i in range(self.n_cons)])\n",
    "    self.waiting_consumers = deque()\n",
    "    self.waiting_producers = deque()\n",
    "    \n",
    "    # These will likely store (id, finish_clock) tuples\n",
    "    self.producing_producers = deque() \n",
    "    self.consuming_consumers = deque()\n",
    "    # --- End of deque conversion ---\n",
    "\n",
    "    self.n_empty_buffers = self.n_buff\n",
    "    self.n_full_buffers = 0\n",
    "    self.n_getting_filled_buffers = 0\n",
    "    self.n_getting_consumed_buffers = 0\n",
    "\n",
    "    # --- 4. Kept these as lists ---\n",
    "    # These look like they are used as arrays (accessed by index),\n",
    "    # so a standard list is the correct choice here.\n",
    "    self.produces_latency_points = [0 for _ in range (self.n_prod)]\n",
    "    self.consumer_latency_points = [0 for _ in range (self.n_cons)]\n",
    "\n",
    "    timer = 0\n",
    "    for i in range(self.max_clocks):\n",
    "    #phase one, arrivals: \n",
    "      while (self.produces_latency_points[self.producing_producers[-1]] == self.pl -1) and self.producing_producers: \n",
    "        x = self.producing_producers.pop()\n",
    "        self.produces_latency_points[x] = 0 \n",
    "        self.n_full_buffers +=1 \n",
    "        self.n_getting_filled_buffers -= 1\n",
    "        self.free_producers.appendleft(x) #arrives \n",
    "        \n",
    "      while (self.consumer_latency_points[self.consuming_consumers[-1]] == self.cl -1) and self.consuming_consumers: \n",
    "        x = self.consuming_consumers.pop()\n",
    "        self.consumer_latency_points[x] = 0 \n",
    "        self.n_empty_buffers +=1 \n",
    "        self.n_getting_consumed_buffers -= 1\n",
    "        self.free_consumers.appendleft(x) #arrives \n",
    "        self.n_jobs -= 1\n",
    "        \n",
    "      #phase 1.1 increments \n",
    "      for x in self.producing_producers: \n",
    "        self.produces_latency_points[x] += 1\n",
    "      \n",
    "      for x in self.consuming_consumers: \n",
    "        self.consumer_latency_points[x] += 1\n",
    "        \n",
    "      #phase 2 schedule new jobs \n",
    "      while(self.waiting_consumers) and (self.n_full_buffers > 0): \n",
    "        x = self.waiting_consumers.pop() \n",
    "        self.n_full_buffers -= 1 \n",
    "        self.n_getting_consumed_buffers += 1\n",
    "        self.consuming_consumers.appendleft(x) \n",
    "        \n",
    "      while(self.waiting_producers) and (self.n_empty_buffers > 0): \n",
    "        x = self.waiting_producers.pop()\n",
    "        self.n_empty_buffers -= 1\n",
    "        self.n_getting_filled_buffers += 1 \n",
    "        self.producing_producers.appendleft(x) \n",
    "        \n",
    "      #phase3 free ones wait for new jobs \n",
    "      \n",
    "      while(self.free_consumers): \n",
    "        x  = self.free_consumers.pop()\n",
    "        self.waiting_consumers.appendleft(x)\n",
    "        \n",
    "      while (self.free_producers): \n",
    "        x = self.free_producers.pop()\n",
    "        self.waiting_producers.appendleft(x)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad07adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================\n",
      "TIMER: 0\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (0 Started)\n",
      "BUFFERS: Empty(6), Full(0), Filling(0), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     [0, 1, 2, 3]\n",
      "  Waiting:  []\n",
      "  Producing: []\n",
      "CONSUMERS:\n",
      "  Free:     [0, 1, 2, 3, 4, 5]\n",
      "  Waiting:  []\n",
      "  Consuming: []\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 1\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (4 Started)\n",
      "BUFFERS: Empty(6), Full(0), Filling(0), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  [3, 2, 1, 0]\n",
      "  Producing: []\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2, 1, 0]\n",
      "  Consuming: []\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 2\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (4 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(4), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2, 1, 0]\n",
      "  Consuming: []\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 3\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (4 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(4), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2, 1, 0]\n",
      "  Consuming: []\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 4\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (4 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(4), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2, 1, 0]\n",
      "  Consuming: []\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 5\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (4 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(4), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2, 1, 0]\n",
      "  Consuming: []\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 6\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (4 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(4), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2, 1, 0]\n",
      "  Consuming: []\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 7\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (8 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(0), Consuming(4)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  [3, 2, 1, 0]\n",
      "  Producing: []\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4]\n",
      "  Consuming: [0, 1, 2, 3]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 8\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (8 Started)\n",
      "BUFFERS: Empty(0), Full(0), Filling(2), Consuming(4)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  [3, 2]\n",
      "  Producing: [0, 1]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4]\n",
      "  Consuming: [0, 1, 2, 3]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 9\n",
      "=====================================================\n",
      "JOBS:    0 / 20 Completed. (8 Started)\n",
      "BUFFERS: Empty(0), Full(0), Filling(2), Consuming(4)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  [3, 2]\n",
      "  Producing: [0, 1]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4]\n",
      "  Consuming: [0, 1, 2, 3]\n",
      "\n",
      "\n",
      "... [simulation running] ...\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 28\n",
      "=====================================================\n",
      "JOBS:    14 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(0), Full(0), Filling(4), Consuming(2)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 1, 0]\n",
      "  Consuming: [2, 3]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 29\n",
      "=====================================================\n",
      "JOBS:    14 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(0), Full(0), Filling(4), Consuming(2)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 1, 0]\n",
      "  Consuming: [2, 3]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 30\n",
      "=====================================================\n",
      "JOBS:    16 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(4), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 1, 0, 3, 2]\n",
      "  Consuming: []\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 31\n",
      "=====================================================\n",
      "JOBS:    16 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(2), Consuming(2)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  [1, 0]\n",
      "  Producing: [2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 1, 0]\n",
      "  Consuming: [2, 3]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 32\n",
      "=====================================================\n",
      "JOBS:    16 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(0), Full(0), Filling(4), Consuming(2)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [2, 3, 0, 1]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 1, 0]\n",
      "  Consuming: [2, 3]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 33\n",
      "=====================================================\n",
      "JOBS:    16 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(0), Full(0), Filling(2), Consuming(4)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  [3, 2]\n",
      "  Producing: [0, 1]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4]\n",
      "  Consuming: [2, 3, 0, 1]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 34\n",
      "=====================================================\n",
      "JOBS:    18 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(0), Full(0), Filling(4), Consuming(2)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2]\n",
      "  Consuming: [0, 1]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 35\n",
      "=====================================================\n",
      "JOBS:    18 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(0), Full(0), Filling(4), Consuming(2)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2]\n",
      "  Consuming: [0, 1]\n",
      "\n",
      "\n",
      "=====================================================\n",
      "TIMER: 36\n",
      "=====================================================\n",
      "JOBS:    20 / 20 Completed. (20 Started)\n",
      "BUFFERS: Empty(2), Full(0), Filling(4), Consuming(0)\n",
      "---\n",
      "PRODUCERS:\n",
      "  Free:     []\n",
      "  Waiting:  []\n",
      "  Producing: [0, 1, 2, 3]\n",
      "CONSUMERS:\n",
      "  Free:     []\n",
      "  Waiting:  [5, 4, 3, 2, 1, 0]\n",
      "  Consuming: []\n",
      "\n",
      "--- SIMULATION FINISHED AT CLOCK 36 ---\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import textwrap\n",
    "\n",
    "class Producer_Consumer:\n",
    "    def __init__(self, n_resources: int, n_producers: int, n_buffers: int, prod_job_latency: int, cons_job_latency: int, n_jobs: int):\n",
    "        \n",
    "        # --- Parameters ---\n",
    "        self.pl = prod_job_latency\n",
    "        self.cl = cons_job_latency\n",
    "        self.n_jobs_total = n_jobs\n",
    "        self.n_w = n_resources\n",
    "        self.n_prod = n_producers\n",
    "        self.n_cons = self.n_w - self.n_prod\n",
    "        self.n_buff = n_buffers\n",
    "        \n",
    "        # Max clock safeguard to prevent infinite loops\n",
    "        self.max_clocks = (self.pl + self.cl + 2) * self.n_jobs_total + 1000 # Added a buffer\n",
    "\n",
    "        # --- Job Counters ---\n",
    "        self.n_jobs_started = 0\n",
    "        self.n_jobs_completed = 0\n",
    "\n",
    "        # --- Worker Pools (using append/pop as stacks) ---\n",
    "        self.free_producers = deque(range(self.n_prod))\n",
    "        self.free_consumers = deque(range(self.n_cons))\n",
    "        self.waiting_consumers = deque()\n",
    "        self.waiting_producers = deque()\n",
    "        \n",
    "        # --- Active Worker Lists (using deque as a set/list) ---\n",
    "        self.producing_producers = deque() \n",
    "        self.consuming_consumers = deque()\n",
    "        \n",
    "        # --- Buffer State Counters ---\n",
    "        self.n_empty_buffers = self.n_buff\n",
    "        self.n_full_buffers = 0\n",
    "        self.n_getting_filled_buffers = 0\n",
    "        self.n_getting_consumed_buffers = 0\n",
    "\n",
    "        # --- Latency Tracking ---\n",
    "        self.produces_latency_points = [0] * self.n_prod\n",
    "        self.consumer_latency_points = [0] * self.n_cons\n",
    "        \n",
    "        # This will hold the history of our simulation\n",
    "        self.state_history = []\n",
    "\n",
    "    def _get_state_repr(self, timer: int) -> str:\n",
    "        \"\"\"Helper method to create a snapshot of the current state.\"\"\"\n",
    "        # Using textwrap to make the output clean\n",
    "        state = f\"\"\"\n",
    "        =====================================================\n",
    "        TIMER: {timer}\n",
    "        =====================================================\n",
    "        JOBS:    {self.n_jobs_completed} / {self.n_jobs_total} Completed. ({self.n_jobs_started} Started)\n",
    "        BUFFERS: Empty({self.n_empty_buffers}), Full({self.n_full_buffers}), Filling({self.n_getting_filled_buffers}), Consuming({self.n_getting_consumed_buffers})\n",
    "        ---\n",
    "        PRODUCERS:\n",
    "          Free:     {list(self.free_producers)}\n",
    "          Waiting:  {list(self.waiting_producers)}\n",
    "          Producing: {list(self.producing_producers)}\n",
    "        CONSUMERS:\n",
    "          Free:     {list(self.free_consumers)}\n",
    "          Waiting:  {list(self.waiting_consumers)}\n",
    "          Consuming: {list(self.consuming_consumers)}\n",
    "        \"\"\"\n",
    "        return textwrap.dedent(state)\n",
    "\n",
    "    def run_simulation(self):\n",
    "        \"\"\"\n",
    "        Runs the full simulation clock by clock.\n",
    "        \n",
    "        The order of operations in each clock cycle is critical:\n",
    "        1. Check for finished work (Reap)\n",
    "        2. Schedule new work (Sow)\n",
    "        3. Assign new jobs to free workers\n",
    "        4. Move any remaining free workers to 'waiting'\n",
    "        5. Increment latency counters for active workers\n",
    "        \"\"\"\n",
    "        timer = 0\n",
    "\n",
    "        # Run until all jobs are *completed*, with a safeguard\n",
    "        while self.n_jobs_completed < self.n_jobs_total:\n",
    "            \n",
    "            # Log the state *before* any changes in this cycle\n",
    "            self.state_history.append(self._get_state_repr(timer))\n",
    "            \n",
    "            if timer > self.max_clocks:\n",
    "                self.state_history.append(\"!!! SIMULATION TIMED OUT !!!\")\n",
    "                break\n",
    "            \n",
    "            # --- PHASE 1: CHECK FOR FINISHED WORK (REAP) ---\n",
    "            # We iterate over a static list() copy to safely remove from the deque\n",
    "            \n",
    "            for producer_id in list(self.producing_producers):\n",
    "                # Check if the job is done (latency counter is at max)\n",
    "                if self.produces_latency_points[producer_id] == self.pl:\n",
    "                    self.producing_producers.remove(producer_id)\n",
    "                    self.produces_latency_points[producer_id] = 0 # Reset counter\n",
    "                    \n",
    "                    self.n_full_buffers += 1\n",
    "                    self.n_getting_filled_buffers -= 1\n",
    "                    self.free_producers.append(producer_id) # Add to FREE pool\n",
    "\n",
    "            for consumer_id in list(self.consuming_consumers):\n",
    "                if self.consumer_latency_points[consumer_id] == self.cl:\n",
    "                    self.consuming_consumers.remove(consumer_id)\n",
    "                    self.consumer_latency_points[consumer_id] = 0 # Reset counter\n",
    "                    \n",
    "                    self.n_empty_buffers += 1\n",
    "                    self.n_getting_consumed_buffers -= 1\n",
    "                    self.free_consumers.append(consumer_id) # Add to FREE pool\n",
    "                    \n",
    "                    self.n_jobs_completed += 1 # A job is fully done!\n",
    "\n",
    "            # --- PHASE 2: SCHEDULE NEW WORK (SOW) ---\n",
    "            # Match waiting workers to available buffers\n",
    "            \n",
    "            while self.waiting_producers and self.n_empty_buffers > 0:\n",
    "                producer_id = self.waiting_producers.pop()\n",
    "                \n",
    "                self.n_empty_buffers -= 1\n",
    "                self.n_getting_filled_buffers += 1\n",
    "                self.producing_producers.append(producer_id) # Move to PRODUCING\n",
    "                \n",
    "            while self.waiting_consumers and self.n_full_buffers > 0:\n",
    "                consumer_id = self.waiting_consumers.pop()\n",
    "                \n",
    "                self.n_full_buffers -= 1\n",
    "                self.n_getting_consumed_buffers += 1\n",
    "                self.consuming_consumers.append(consumer_id) # Move to CONSUMING\n",
    "\n",
    "            # --- PHASE 3: ASSIGN NEW JOBS & MOVE FREE TO WAITING ---\n",
    "            # This is your explicit model of the barrier `arrive` phase\n",
    "            \n",
    "            # First, assign new job \"tickets\" to free producers\n",
    "            while self.free_producers and self.n_jobs_started < self.n_jobs_total:\n",
    "                producer_id = self.free_producers.pop()\n",
    "                self.waiting_producers.append(producer_id) # Move to WAITING\n",
    "                self.n_jobs_started += 1\n",
    "            \n",
    "            # Second, move *all remaining* free workers to the waiting state\n",
    "            # This models them \"arriving\" and now \"waiting\" for the next cycle\n",
    "            while self.free_producers:\n",
    "                self.waiting_producers.append(self.free_producers.pop())\n",
    "                \n",
    "            while self.free_consumers:\n",
    "                self.waiting_consumers.append(self.free_consumers.pop())\n",
    "\n",
    "            # --- PHASE 4: INCREMENT LATENCY COUNTERS ---\n",
    "            # This must happen *last*, after all assignments are done.\n",
    "            # We increment the timer for any worker that is *actively* working.\n",
    "            \n",
    "            for producer_id in self.producing_producers:\n",
    "                self.produces_latency_points[producer_id] += 1\n",
    "            \n",
    "            for consumer_id in self.consuming_consumers:\n",
    "                self.consumer_latency_points[consumer_id] += 1\n",
    "                \n",
    "            # --- END OF CYCLE ---\n",
    "            timer += 1\n",
    "        \n",
    "        # Log the final state\n",
    "        self.state_history.append(self._get_state_repr(timer))\n",
    "        self.state_history.append(f\"--- SIMULATION FINISHED AT CLOCK {timer} ---\")\n",
    "        \n",
    "        return self.state_history\n",
    "\n",
    "# --- Example of how to run it ---\n",
    "\n",
    "# Create the simulation\n",
    "sim = Producer_Consumer(\n",
    "    n_resources=10, \n",
    "    n_producers=4,    # 4 producers\n",
    "    n_buffers=6,      # 6 buffers\n",
    "    prod_job_latency=5, # 5 clock cycles to produce\n",
    "    cons_job_latency=3, # 3 clock cycles to consume\n",
    "    n_jobs=20         # 20 total jobs\n",
    ")\n",
    "\n",
    "# Run it\n",
    "history = sim.run_simulation()\n",
    "\n",
    "# Print the first 10 and last 10 states\n",
    "for state in history[:10]:\n",
    "    print(state)\n",
    "\n",
    "print(\"\\n... [simulation running] ...\\n\")\n",
    "\n",
    "for state in history[-10:]:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb92b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9561959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"/tmp/tmpkxacqu0t\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter\n",
    "\n",
    "from nvcc4jupyter import set_defaults\n",
    "set_defaults(compiler_args='-arch=sm_100a -Xptxas=-v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb07c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(23): error: expected a \";\"\n",
      "  __attribute__((device)) void producer(barrier ready[], barrier filled[], float* As, float*Bs, float*A, float*B)\n",
      "  ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(47): warning #12-D: parsing restarts here after previous syntax error\n",
      "      barrier::arrival_token token = filled[buffer_idx].arrive();\n",
      "                                                                ^\n",
      "\n",
      "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(48): error: expected a declaration\n",
      "    }\n",
      "    ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(72): warning #12-D: parsing restarts here after previous syntax error\n",
      "            C[As_true_row*BN + Bs_true_col] += As[buffer_idx][As_true_row*BN + As_col] * Bs[buffer_idx][Bs_row*BN + Bs_true_col];\n",
      "                                                                                                                                ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(73): error: expected a declaration\n",
      "          }\n",
      "          ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(76): warning #12-D: parsing restarts here after previous syntax error\n",
      "      barrier::arrival_token token = ready[buffer_idx].arrive();\n",
      "                                                               ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(77): error: expected a declaration\n",
      "    }\n",
      "    ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(123): warning #12-D: parsing restarts here after previous syntax error\n",
      "    cudaMemcpy(C_h, C_d, size_C, cudaMemcpyDeviceToHost);\n",
      "                                                        ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(124): error: expected a declaration\n",
      "    for (int i = 0; i < 100; i++)\n",
      "    ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(128): warning #12-D: parsing restarts here after previous syntax error\n",
      "    return 0;\n",
      "            ^\n",
      "\n",
      "/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu(129): error: expected a declaration\n",
      "  }\n",
      "  ^\n",
      "\n",
      "6 errors detected in the compilation of \"/tmp/tmpkxacqu0t/67cbe858-af9f-4bca-ac68-29bab99fc28d/single_file.cu\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda.h> \n",
    "#include<cuda_runtime.h> \n",
    "#include <cuda/barrier>\n",
    "#include <cooperative_groups.h>\n",
    "\n",
    "namespace cg = cooperative_groups;\n",
    "using barrier = cuda::barrier<cuda::thread_scope_block>;\n",
    "\n",
    "\n",
    "constexpr int N = 4096; \n",
    "constexpr int BN = 32; \n",
    "constexpr int N_blocks = 1;\n",
    "constexpr int n_warps = 16;\n",
    "constexpr int n_producer_warps = 8;\n",
    "constexpr int n_consumer_warps = n_warps - n_producer_warps;\n",
    "\n",
    "constexpr int block_size = n_warps*32;\n",
    "constexpr int N_jobs = N//BN; \n",
    "\n",
    "\n",
    "__device__ void producer(barrier ready[], barrier filled[], float* As, float*Bs, float*A, float*B)\n",
    "{\n",
    "  for (int k = 0; k < N; k+= BN)\n",
    "  {\n",
    "    //#at any iteration, producer threads need to arrive at wait until that iterations's buffer is ready. \n",
    "    int buffer_idx = k % 2; \n",
    "    ready[buffer_idx].arrive_and_wait(); \n",
    "    //#okay now, n_producer_warps has n_producer_Warps*32 threads, and they need to load stuff of As and Bs. \n",
    "    //#we have 8 producer warps, so we treat out thread block like (32,8) and do float 4 loads. \n",
    "    int t = threadIdx.x; \n",
    "    int row = t // 8; \n",
    "    int col = t % 8;\n",
    "    int A_row = 0 + row; \n",
    "    int A_col = k + 4*col; \n",
    "    int As_row = row; \n",
    "    int As_col = 4*col; \n",
    "    int B_row = k + row; \n",
    "    int B_col = 0 + 4*col; \n",
    "    int Bs_row = row; \n",
    "    int Bs_col = 4*col;\n",
    "    \n",
    "    *reinterpret_cast<float4*>(&As[buffer_idx][As_row*BN + As_col]) = *reinterpret_cast<float4*>(&A[A_row*N + A_col])\n",
    "    *reinterpret_cast<float4*>(&Bs[buffer_idx][Bs_row*BN + Bs_col]) = *reinterpret_cast<float4*>(&B[B_row*BN + B_col])\n",
    "    \n",
    "    barrier::arrival_token token = filled[buffer_idx].arrive();\n",
    "  }\n",
    "}\n",
    "__device__ void consumer(barrier ready[], barrier filled[], float* As, float*Bs, float*C)\n",
    "{\n",
    "  barrier::arrival_token token1 = ready[0].arrive(); /* buffer_0 is ready for initial fill */\n",
    "  barrier::arrival_token token2 = ready[1].arrive(); /* buffer_1 is ready for initial fill */\n",
    "  for (int k = 0; k < N; k+= BN)\n",
    "  {\n",
    "    //#at any iteration, consumer threads need to arrive at wait until that iterations's buffer is full. \n",
    "    int buffer_idx = k % 2; \n",
    "    filled[buffer_idx].arrive_and_wait(); \n",
    "    int t = threadIdx.x - (8*32); \n",
    "    int As_row = t // 32; \n",
    "    int As_col = t % 32; \n",
    "    int Bs_row = As_col; \n",
    "    int Bs_col = As_row; \n",
    "    \n",
    "    //#again we have to do a 32x32 matmul, but we have (32x8) threads, which means, we need to do  A(8x32) B(32x8) matmuls\n",
    "    for (int i = 0; i < 4; i++)\n",
    "    {\n",
    "      for (int j = 0; j < 4; j++)\n",
    "        {\n",
    "          int As_true_row = As_row + 4*i \n",
    "          int Bs_true_col = Bs_col + 4*j \n",
    "          C[As_true_row*BN + Bs_true_col] += As[buffer_idx][As_true_row*BN + As_col] * Bs[buffer_idx][Bs_row*BN + Bs_true_col];\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    barrier::arrival_token token = ready[buffer_idx].arrive(); \n",
    "  }\n",
    "    \n",
    "}\n",
    "\n",
    "__global__ void matmul(float*A, float*B, float*C)\n",
    "{\n",
    "  __shared__ float As[2][BN*BN];\n",
    "  __shared__ float Bs[2][BN*BN];\n",
    "  __shared__ barrier bar[4]; \n",
    "  int t = threadIdx.x; \n",
    "  if (t<4): \n",
    "    init(bar + t, block_size);\n",
    "  __syncthreads(); \n",
    "  \n",
    "  if (t < n_producer_warps*32)\n",
    "    producer(bar, bar + 2, As, Bs, A, B)\n",
    "  else \n",
    "    consumer(bar, bar + 2, As, Bs, C)\n",
    "  \n",
    "  __syncthreads();\n",
    "  \n",
    "  \n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  float *A_h, *A_d, *B_h, *B_d, *C_h, *C_d; \n",
    "  size_t size = N*BN*sizeof(float); \n",
    "  size_t size_C = BN*BN*sizeof(float);\n",
    "  cudaHostAlloc(&A_h, size, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&B_h, size, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&C_h, size_C, cudaHostAllocDefault);\n",
    "  cudaMalloc(&A_d, size);\n",
    "  cudaMalloc(&B_d, size); \n",
    "  cudaMalloc(&C_d, size_C);\n",
    "  for (int i = 0; i < BN*N; i++)\n",
    "  {\n",
    "    A_h[i] = (float) i / 10000.0; \n",
    "    B_h[i] = (float) i / 10000.0;\n",
    "  }\n",
    "  cudaMemcpy(A_d, A_h, size, cudaMemcpyHostToDevice);\n",
    "  cudaMemcpy(B_d, B_h, size, cudaMemcpyHostToDevice);\n",
    "  \n",
    "  matmul<<<N_blocks, block_size>>>(A_d, B_d, C_d);\n",
    "  \n",
    "  cudaDeviceSynchronize();\n",
    "  cudaMemcpy(C_h, C_d, size_C, cudaMemcpyDeviceToHost);\n",
    "  for (int i = 0; i < 100; i++)\n",
    "  {\n",
    "    printf(\"%f, \\n\", C_h[i]);\n",
    "  }\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017f4f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 elements of C:\n",
      "10061716.000000, \n",
      "10268372.000000, \n",
      "10475028.000000, \n",
      "10681684.000000, \n",
      "10207740.000000, \n",
      "10414396.000000, \n",
      "10621052.000000, \n",
      "10827708.000000, \n",
      "10304564.000000, \n",
      "10511220.000000, \n",
      "10717876.000000, \n",
      "10924532.000000, \n",
      "10352188.000000, \n",
      "10558844.000000, \n",
      "10765500.000000, \n",
      "10972156.000000, \n",
      "10350612.000000, \n",
      "10557268.000000, \n",
      "10763924.000000, \n",
      "10970580.000000, \n",
      "10299836.000000, \n",
      "10506492.000000, \n",
      "10713148.000000, \n",
      "10919804.000000, \n",
      "10199860.000000, \n",
      "10406516.000000, \n",
      "10613172.000000, \n",
      "10819828.000000, \n",
      "10060384.000000, \n",
      "10267040.000000, \n",
      "10473696.000000, \n",
      "10680352.000000, \n",
      "10062452.000000, \n",
      "10269124.000000, \n",
      "10475796.000000, \n",
      "10682468.000000, \n",
      "9864140.000000, \n",
      "10070812.000000, \n",
      "10277484.000000, \n",
      "10484156.000000, \n",
      "10026628.000000, \n",
      "10233300.000000, \n",
      "10439972.000000, \n",
      "10646644.000000, \n",
      "10139916.000000, \n",
      "10346588.000000, \n",
      "10553260.000000, \n",
      "10759932.000000, \n",
      "10204004.000000, \n",
      "10410676.000000, \n",
      "10617348.000000, \n",
      "10824020.000000, \n",
      "10218892.000000, \n",
      "10425564.000000, \n",
      "10632236.000000, \n",
      "10838908.000000, \n",
      "10184580.000000, \n",
      "10391252.000000, \n",
      "10597924.000000, \n",
      "10804596.000000, \n",
      "10110368.000000, \n",
      "10317040.000000, \n",
      "10523712.000000, \n",
      "10730384.000000, \n",
      "10112388.000000, \n",
      "10319076.000000, \n",
      "10525764.000000, \n",
      "10732452.000000, \n",
      "9979740.000000, \n",
      "10186428.000000, \n",
      "10393116.000000, \n",
      "10599804.000000, \n",
      "9797892.000000, \n",
      "10004580.000000, \n",
      "10211268.000000, \n",
      "10417956.000000, \n",
      "9976844.000000, \n",
      "10183532.000000, \n",
      "10390220.000000, \n",
      "10596908.000000, \n",
      "10106596.000000, \n",
      "10313284.000000, \n",
      "10519972.000000, \n",
      "10726660.000000, \n",
      "10187148.000000, \n",
      "10393836.000000, \n",
      "10600524.000000, \n",
      "10807212.000000, \n",
      "10218500.000000, \n",
      "10425188.000000, \n",
      "10631876.000000, \n",
      "10838564.000000, \n",
      "10209552.000000, \n",
      "10416240.000000, \n",
      "10622928.000000, \n",
      "10829616.000000, \n",
      "10211524.000000, \n",
      "10418228.000000, \n",
      "10624932.000000, \n",
      "10831636.000000, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "// #include<cuda.h> // Not strictly needed when using cuda_runtime.h\n",
    "#include<cuda_runtime.h> \n",
    "#include <cuda/barrier>\n",
    "#include <cooperative_groups.h> // Not used in this fix, but fine to include\n",
    "\n",
    "// namespace cg = cooperative_groups; // Not used\n",
    "using barrier = cuda::barrier<cuda::thread_scope_block>;\n",
    "\n",
    "\n",
    "constexpr int N = 4096; \n",
    "constexpr int BN = 32; \n",
    "constexpr int N_blocks = 1;\n",
    "constexpr int n_warps = 16;\n",
    "constexpr int n_producer_warps = 8;\n",
    "constexpr int n_consumer_warps = n_warps - n_producer_warps;\n",
    "\n",
    "constexpr int block_size = n_warps*32; // 512 threads\n",
    "// constexpr int N_jobs = N / BN; // Fixed syntax, but this constant wasn't used\n",
    "\n",
    "\n",
    "// Note the change in As and Bs types:\n",
    "// They are now pointers to arrays of size [BN*BN], which is what __shared__ As[2][BN*BN] decays to.\n",
    "__device__ void producer(\n",
    "    barrier ready[], \n",
    "    barrier filled[], \n",
    "    float (*As)[BN*BN], // Correct type for __shared__ array\n",
    "    float (*Bs)[BN*BN], // Correct type for __shared__ array\n",
    "    float* A, \n",
    "    float* B)\n",
    "{\n",
    "  for (int k = 0; k < N; k += BN)\n",
    "  {\n",
    "    // BUG FIX: The buffer index must be based on the *iteration*, not the value of k.\n",
    "    // k=0 -> idx=0. k=BN -> idx=1. k=2*BN -> idx=0.\n",
    "    int buffer_idx = (k / BN) % 2; \n",
    "    \n",
    "    ready[buffer_idx].arrive_and_wait(); \n",
    "    \n",
    "    int t = threadIdx.x; // 0..255 for producers\n",
    "    int row = t / 8; // BUG FIX: C++ integer division is /\n",
    "    int col = t % 8;\n",
    "    \n",
    "    int A_row = row; \n",
    "    int A_col = k + 4*col; \n",
    "    int As_row = row; \n",
    "    int As_col = 4*col; \n",
    "    \n",
    "    int B_row = k + row; \n",
    "    int B_col = 4*col; \n",
    "    int Bs_row = row; \n",
    "    int Bs_col = 4*col;\n",
    "    \n",
    "    // Perform the 128-bit (float4) loads and stores\n",
    "    \n",
    "    // Load from A (BN x N) matrix: A[A_row, A_col] -> A[row, k + 4*col]\n",
    "    *reinterpret_cast<float4*>(&As[buffer_idx][As_row*BN + As_col]) = \n",
    "        *reinterpret_cast<float4*>(&A[A_row*N + A_col]); // BUG FIX: Added semicolon\n",
    "    \n",
    "    // Load from B (N x BN) matrix: B[B_row, B_col] -> B[k + row, 4*col]\n",
    "    // BUG FIX: B's index is B[row, col] = row * BN + col. Your code used N.\n",
    "    *reinterpret_cast<float4*>(&Bs[buffer_idx][Bs_row*BN + Bs_col]) = \n",
    "        *reinterpret_cast<float4*>(&B[B_row*BN + B_col]); // BUG FIX: Added semicolon\n",
    "    \n",
    "    // Signal that this buffer is full\n",
    "    filled[buffer_idx].arrive();\n",
    "  }\n",
    "}\n",
    "\n",
    "__device__ void consumer(\n",
    "    barrier ready[], \n",
    "    barrier filled[], \n",
    "    float (*As)[BN*BN], \n",
    "    float (*Bs)[BN*BN], \n",
    "    float* C)\n",
    "{\n",
    "  // BUG FIX (Major Logic): Accumulation must happen in registers.\n",
    "  // We have 256 consumer threads. Map to a 8x32 grid.\n",
    "  // Each thread will compute 4 elements of the final C matrix.\n",
    "  \n",
    "  int t = threadIdx.x - (n_producer_warps * 32); // 0..255 for consumers\n",
    "  int thr_row = t / 32; // Thread's base row (0..7)\n",
    "  int thr_col = t % 32; // Thread's column (0..31)\n",
    "  \n",
    "  // These registers will accumulate C[thr_row + (0, 8, 16, 24), thr_col]\n",
    "  float C_reg[4] = {0.0f, 0.0f, 0.0f, 0.0f};\n",
    "\n",
    "  // Signal that both buffers are ready to be filled for the first time\n",
    "  ready[0].arrive();\n",
    "  ready[1].arrive();\n",
    "\n",
    "  for (int k = 0; k < N; k += BN)\n",
    "  {\n",
    "    // BUG FIX: Correct buffer index logic\n",
    "    int buffer_idx = (k / BN) % 2; \n",
    "    \n",
    "    // Wait for the producer to fill this buffer\n",
    "    filled[buffer_idx].arrive_and_wait(); \n",
    "    \n",
    "    // Pointers to the correct shared memory tile\n",
    "    float* A_tile = As[buffer_idx];\n",
    "    float* B_tile = Bs[buffer_idx];\n",
    "\n",
    "    // --- Perform tile-level matrix multiplication ---\n",
    "    // C_tile = A_tile * B_tile\n",
    "    // Each thread computes 4 dot products\n",
    "    for (int dot_k = 0; dot_k < BN; dot_k++)\n",
    "    {\n",
    "      C_reg[0] += A_tile[(thr_row +  0)*BN + dot_k] * B_tile[dot_k*BN + thr_col];\n",
    "      C_reg[1] += A_tile[(thr_row +  8)*BN + dot_k] * B_tile[dot_k*BN + thr_col];\n",
    "      C_reg[2] += A_tile[(thr_row + 16)*BN + dot_k] * B_tile[dot_k*BN + thr_col];\n",
    "      C_reg[3] += A_tile[(thr_row + 24)*BN + dot_k] * B_tile[dot_k*BN + thr_col];\n",
    "    }\n",
    "  \n",
    "    // Signal that this buffer is now ready to be refilled\n",
    "    ready[buffer_idx].arrive(); \n",
    "  }\n",
    "  \n",
    "  // After all k-loops, write accumulated registers to global memory\n",
    "  C[(thr_row +  0)*BN + thr_col] = C_reg[0];\n",
    "  C[(thr_row +  8)*BN + thr_col] = C_reg[1];\n",
    "  C[(thr_row + 16)*BN + thr_col] = C_reg[2];\n",
    "  C[(thr_row + 24)*BN + thr_col] = C_reg[3];\n",
    "}\n",
    "\n",
    "__global__ void matmul(float*A, float*B, float*C)\n",
    "{\n",
    "  __shared__ float As[2][BN*BN];\n",
    "  __shared__ float Bs[2][BN*BN];\n",
    "  \n",
    "  // We need 4 barriers: 2 for 'ready' (ping/pong) and 2 for 'filled' (ping/pong)\n",
    "  __shared__ barrier bar[4]; \n",
    "  \n",
    "  int t = threadIdx.x; \n",
    "  \n",
    "  // BUG FIX: C++ syntax for if\n",
    "  // BUG FIX: init() is a member function\n",
    "  // Initialize all 4 barriers. All 512 threads are expected to participate\n",
    "  // in the producer/consumer pattern, so the count is block_size.\n",
    "  if (t < 4) \n",
    "    init(bar + t, block_size); \n",
    "  \n",
    "  __syncthreads(); \n",
    "  \n",
    "  if (t < n_producer_warps*32)\n",
    "    // bar[0], bar[1] are 'ready' barriers\n",
    "    // bar[2], bar[3] are 'filled' barriers\n",
    "    producer(bar, bar + 2, As, Bs, A, B);\n",
    "  else \n",
    "    consumer(bar, bar + 2, As, Bs, C);\n",
    "  \n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  float *A_h, *A_d, *B_h, *B_d, *C_h, *C_d; \n",
    "  \n",
    "  // A is (BN x N) -> (32 x 4096)\n",
    "  // B is (N x BN) -> (4096 x 32)\n",
    "  // C is (BN x BN) -> (32 x 32)\n",
    "  size_t size_A = BN*N*sizeof(float); \n",
    "  size_t size_B = N*BN*sizeof(float); \n",
    "  size_t size_C = BN*BN*sizeof(float);\n",
    "  \n",
    "  cudaHostAlloc(&A_h, size_A, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&B_h, size_B, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&C_h, size_C, cudaHostAllocDefault);\n",
    "  \n",
    "  cudaMalloc(&A_d, size_A);\n",
    "  cudaMalloc(&B_d, size_B); \n",
    "  cudaMalloc(&C_d, size_C);\n",
    "  \n",
    "  // Initialize A and B\n",
    "  for (int i = 0; i < BN*N; i++)\n",
    "  {\n",
    "    A_h[i] = (float) (i % 100) + 1.0f; // Simpler test data\n",
    "    B_h[i] = (float) (i % 100) + 1.0f;\n",
    "  }\n",
    "  \n",
    "  // BUG FIX: C must be zeroed before the kernel, as the kernel performs an\n",
    "  // accumulation (C += A*B), which in our case is handled by C_reg[4] = {0.0f...}\n",
    "  // But if C were used for reduction, this would be critical.\n",
    "  // It's still critical here because our kernel *writes* C, it doesn't add to it.\n",
    "  // If the consumer threads didn't write to *all* of C, we would need this.\n",
    "  // Better safe than sorry.\n",
    "  cudaMemset(C_d, 0, size_C); \n",
    "\n",
    "  cudaMemcpy(A_d, A_h, size_A, cudaMemcpyHostToDevice);\n",
    "  cudaMemcpy(B_d, B_h, size_B, cudaMemcpyHostToDevice);\n",
    "  \n",
    "  matmul<<<N_blocks, block_size>>>(A_d, B_d, C_d);\n",
    "  \n",
    "  cudaError_t err = cudaGetLastError();\n",
    "  if (err != cudaSuccess) {\n",
    "    printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
    "  }\n",
    "  \n",
    "  cudaDeviceSynchronize();\n",
    "  \n",
    "  cudaMemcpy(C_h, C_d, size_C, cudaMemcpyDeviceToHost);\n",
    "  \n",
    "  printf(\"First 100 elements of C:\\n\");\n",
    "  for (int i = 0; i < 100; i++)\n",
    "  {\n",
    "    printf(\"%f, \\n\", C_h[i]);\n",
    "  }\n",
    "  \n",
    "  cudaFree(A_d);\n",
    "  cudaFree(B_d);\n",
    "  cudaFree(C_d);\n",
    "  cudaFreeHost(A_h);\n",
    "  cudaFreeHost(B_h);\n",
    "  cudaFreeHost(C_h);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82465fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 elements of C:\n",
      "10061716.000000, \n",
      "10268372.000000, \n",
      "10475028.000000, \n",
      "10681684.000000, \n",
      "10207740.000000, \n",
      "10414396.000000, \n",
      "10621052.000000, \n",
      "10827708.000000, \n",
      "10304564.000000, \n",
      "10511220.000000, \n",
      "10717876.000000, \n",
      "10924532.000000, \n",
      "10352188.000000, \n",
      "10558844.000000, \n",
      "10765500.000000, \n",
      "10972156.000000, \n",
      "10350612.000000, \n",
      "10557268.000000, \n",
      "10763924.000000, \n",
      "10970580.000000, \n",
      "10299836.000000, \n",
      "10506492.000000, \n",
      "10713148.000000, \n",
      "10919804.000000, \n",
      "10199860.000000, \n",
      "10406516.000000, \n",
      "10613172.000000, \n",
      "10819828.000000, \n",
      "10060384.000000, \n",
      "10267040.000000, \n",
      "10473696.000000, \n",
      "10680352.000000, \n",
      "10062452.000000, \n",
      "10269124.000000, \n",
      "10475796.000000, \n",
      "10682468.000000, \n",
      "9864140.000000, \n",
      "10070812.000000, \n",
      "10277484.000000, \n",
      "10484156.000000, \n",
      "10026628.000000, \n",
      "10233300.000000, \n",
      "10439972.000000, \n",
      "10646644.000000, \n",
      "10139916.000000, \n",
      "10346588.000000, \n",
      "10553260.000000, \n",
      "10759932.000000, \n",
      "10204004.000000, \n",
      "10410676.000000, \n",
      "10617348.000000, \n",
      "10824020.000000, \n",
      "10218892.000000, \n",
      "10425564.000000, \n",
      "10632236.000000, \n",
      "10838908.000000, \n",
      "10184580.000000, \n",
      "10391252.000000, \n",
      "10597924.000000, \n",
      "10804596.000000, \n",
      "10110368.000000, \n",
      "10317040.000000, \n",
      "10523712.000000, \n",
      "10730384.000000, \n",
      "10112388.000000, \n",
      "10319076.000000, \n",
      "10525764.000000, \n",
      "10732452.000000, \n",
      "9979740.000000, \n",
      "10186428.000000, \n",
      "10393116.000000, \n",
      "10599804.000000, \n",
      "9797892.000000, \n",
      "10004580.000000, \n",
      "10211268.000000, \n",
      "10417956.000000, \n",
      "9976844.000000, \n",
      "10183532.000000, \n",
      "10390220.000000, \n",
      "10596908.000000, \n",
      "10106596.000000, \n",
      "10313284.000000, \n",
      "10519972.000000, \n",
      "10726660.000000, \n",
      "10187148.000000, \n",
      "10393836.000000, \n",
      "10600524.000000, \n",
      "10807212.000000, \n",
      "10218500.000000, \n",
      "10425188.000000, \n",
      "10631876.000000, \n",
      "10838564.000000, \n",
      "10209552.000000, \n",
      "10416240.000000, \n",
      "10622928.000000, \n",
      "10829616.000000, \n",
      "10211524.000000, \n",
      "10418228.000000, \n",
      "10624932.000000, \n",
      "10831636.000000, \n",
      "\n",
      "--- Performance ---\n",
      "Kernel Time: 22.574593 ms\n",
      "Total FLOPs: 8.388608e+06\n",
      "GFLOPS/s:    0.371595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h> \n",
    "#include <cuda/barrier>\n",
    "\n",
    "using barrier = cuda::barrier<cuda::thread_scope_block>;\n",
    "\n",
    "constexpr int N = 4096; \n",
    "constexpr int BN = 32; \n",
    "constexpr int N_blocks = 1;\n",
    "constexpr int n_warps = 16;\n",
    "constexpr int n_producer_warps = 8;\n",
    "constexpr int n_consumer_warps = n_warps - n_producer_warps;\n",
    "constexpr int block_size = n_warps*32;\n",
    "\n",
    "__device__ void producer(\n",
    "    barrier ready[], \n",
    "    barrier filled[], \n",
    "    float (*As)[BN*BN], \n",
    "    float (*Bs)[BN*BN], \n",
    "    float* A, \n",
    "    float* B)\n",
    "{\n",
    "  for (int k = 0; k < N; k += BN)\n",
    "  {\n",
    "    int buffer_idx = (k / BN) % 2; \n",
    "    \n",
    "    ready[buffer_idx].arrive_and_wait(); \n",
    "    \n",
    "    int t = threadIdx.x;\n",
    "    int row = t / 8;\n",
    "    int col = t % 8;\n",
    "    \n",
    "    int A_row = row; \n",
    "    int A_col = k + 4*col; \n",
    "    int As_row = row; \n",
    "    int As_col = 4*col; \n",
    "    \n",
    "    int B_row = k + row; \n",
    "    int B_col = 4*col; \n",
    "    int Bs_row = row; \n",
    "    int Bs_col = 4*col;\n",
    "    \n",
    "    *reinterpret_cast<float4*>(&As[buffer_idx][As_row*BN + As_col]) = \n",
    "        *reinterpret_cast<float4*>(&A[A_row*N + A_col]);\n",
    "    \n",
    "    *reinterpret_cast<float4*>(&Bs[buffer_idx][Bs_row*BN + Bs_col]) = \n",
    "        *reinterpret_cast<float4*>(&B[B_row*BN + B_col]);\n",
    "    \n",
    "    filled[buffer_idx].arrive();\n",
    "  }\n",
    "}\n",
    "\n",
    "__device__ void consumer(\n",
    "    barrier ready[], \n",
    "    barrier filled[], \n",
    "    float (*As)[BN*BN], \n",
    "    float (*Bs)[BN*BN], \n",
    "    float* C)\n",
    "{\n",
    "  int t = threadIdx.x - (n_producer_warps * 32);\n",
    "  int thr_row = t / 32;\n",
    "  int thr_col = t % 32;\n",
    "  \n",
    "  float C_reg[4] = {0.0f, 0.0f, 0.0f, 0.0f};\n",
    "\n",
    "  ready[0].arrive();\n",
    "  ready[1].arrive();\n",
    "\n",
    "  for (int k = 0; k < N; k += BN)\n",
    "  {\n",
    "    int buffer_idx = (k / BN) % 2; \n",
    "    \n",
    "    filled[buffer_idx].arrive_and_wait(); \n",
    "    \n",
    "    float* A_tile = As[buffer_idx];\n",
    "    float* B_tile = Bs[buffer_idx];\n",
    "\n",
    "    for (int dot_k = 0; dot_k < BN; dot_k++)\n",
    "    {\n",
    "      C_reg[0] += A_tile[(thr_row +  0)*BN + dot_k] * B_tile[dot_k*BN + thr_col];\n",
    "      C_reg[1] += A_tile[(thr_row +  8)*BN + dot_k] * B_tile[dot_k*BN + thr_col];\n",
    "      C_reg[2] += A_tile[(thr_row + 16)*BN + dot_k] * B_tile[dot_k*BN + thr_col];\n",
    "      C_reg[3] += A_tile[(thr_row + 24)*BN + dot_k] * B_tile[dot_k*BN + thr_col];\n",
    "    }\n",
    "  \n",
    "    ready[buffer_idx].arrive(); \n",
    "  }\n",
    "  \n",
    "  C[(thr_row +  0)*BN + thr_col] = C_reg[0];\n",
    "  C[(thr_row +  8)*BN + thr_col] = C_reg[1];\n",
    "  C[(thr_row + 16)*BN + thr_col] = C_reg[2];\n",
    "  C[(thr_row + 24)*BN + thr_col] = C_reg[3];\n",
    "}\n",
    "\n",
    "__global__ void matmul(float*A, float*B, float*C)\n",
    "{\n",
    "  __shared__ float As[2][BN*BN];\n",
    "  __shared__ float Bs[2][BN*BN];\n",
    "  \n",
    "  __shared__ barrier bar[4]; \n",
    "  \n",
    "  int t = threadIdx.x; \n",
    "  \n",
    "  if (t < 4) \n",
    "   init(bar + t, block_size);\n",
    "  \n",
    "  __syncthreads(); \n",
    "  \n",
    "  if (t < n_producer_warps*32)\n",
    "    producer(bar, bar + 2, As, Bs, A, B);\n",
    "  else \n",
    "    consumer(bar, bar + 2, As, Bs, C);\n",
    "  \n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  float *A_h, *A_d, *B_h, *B_d, *C_h, *C_d; \n",
    "  \n",
    "  size_t size_A = BN*N*sizeof(float); \n",
    "  size_t size_B = N*BN*sizeof(float); \n",
    "  size_t size_C = BN*BN*sizeof(float);\n",
    "  \n",
    "  cudaHostAlloc(&A_h, size_A, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&B_h, size_B, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&C_h, size_C, cudaHostAllocDefault);\n",
    "  \n",
    "  cudaMalloc(&A_d, size_A);\n",
    "  cudaMalloc(&B_d, size_B); \n",
    "  cudaMalloc(&C_d, size_C);\n",
    "  \n",
    "  for (int i = 0; i < BN*N; i++)\n",
    "  {\n",
    "    A_h[i] = (float) (i % 100) + 1.0f;\n",
    "    B_h[i] = (float) (i % 100) + 1.0f;\n",
    "  }\n",
    "  \n",
    "  cudaMemset(C_d, 0, size_C); \n",
    "\n",
    "  cudaMemcpy(A_d, A_h, size_A, cudaMemcpyHostToDevice);\n",
    "  cudaMemcpy(B_d, B_h, size_B, cudaMemcpyHostToDevice);\n",
    "  \n",
    "  cudaEvent_t start, stop;\n",
    "  float elapsedTime_ms;\n",
    "  cudaEventCreate(&start);\n",
    "  cudaEventCreate(&stop);\n",
    "\n",
    "  cudaEventRecord(start);\n",
    "  \n",
    "  matmul<<<N_blocks, block_size>>>(A_d, B_d, C_d);\n",
    "  \n",
    "  cudaEventRecord(stop);\n",
    "  cudaEventSynchronize(stop);\n",
    "  cudaEventElapsedTime(&elapsedTime_ms, start, stop);\n",
    "  \n",
    "  cudaError_t err = cudaGetLastError();\n",
    "  if (err != cudaSuccess) {\n",
    "    printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
    "  }\n",
    "  \n",
    "  cudaMemcpy(C_h, C_d, size_C, cudaMemcpyDeviceToHost);\n",
    "  \n",
    "  printf(\"First 100 elements of C:\\n\");\n",
    "  for (int i = 0; i < 100; i++)\n",
    "  {\n",
    "    printf(\"%f, \\n\", C_h[i]);\n",
    "  }\n",
    "  \n",
    "  double total_flops = (double)BN * (double)BN * (2.0 * (double)N);\n",
    "  double gflops_per_sec = (total_flops / 1e9) / (elapsedTime_ms / 1000.0);\n",
    "\n",
    "  printf(\"\\n--- Performance ---\\n\");\n",
    "  printf(\"Kernel Time: %f ms\\n\", elapsedTime_ms);\n",
    "  printf(\"Total FLOPs: %e\\n\", total_flops);\n",
    "  printf(\"GFLOPS/s:    %f\\n\", gflops_per_sec);\n",
    "  \n",
    "  cudaEventDestroy(start);\n",
    "  cudaEventDestroy(stop);\n",
    "  \n",
    "  cudaFree(A_d);\n",
    "  cudaFree(B_d);\n",
    "  cudaFree(C_d);\n",
    "  cudaFreeHost(A_h);\n",
    "  cudaFreeHost(B_h);\n",
    "  cudaFreeHost(C_h);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e33b5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 elements of C:\n",
      "10061716.000000, \n",
      "10268372.000000, \n",
      "10475028.000000, \n",
      "10681684.000000, \n",
      "10207740.000000, \n",
      "10414396.000000, \n",
      "10621052.000000, \n",
      "10827708.000000, \n",
      "10304564.000000, \n",
      "10511220.000000, \n",
      "10717876.000000, \n",
      "10924532.000000, \n",
      "10352188.000000, \n",
      "10558844.000000, \n",
      "10765500.000000, \n",
      "10972156.000000, \n",
      "10350612.000000, \n",
      "10557268.000000, \n",
      "10763924.000000, \n",
      "10970580.000000, \n",
      "10299836.000000, \n",
      "10506492.000000, \n",
      "10713148.000000, \n",
      "10919804.000000, \n",
      "10199860.000000, \n",
      "10406516.000000, \n",
      "10613172.000000, \n",
      "10819828.000000, \n",
      "10060384.000000, \n",
      "10267040.000000, \n",
      "10473696.000000, \n",
      "10680352.000000, \n",
      "10062452.000000, \n",
      "10269124.000000, \n",
      "10475796.000000, \n",
      "10682468.000000, \n",
      "9864140.000000, \n",
      "10070812.000000, \n",
      "10277484.000000, \n",
      "10484156.000000, \n",
      "10026628.000000, \n",
      "10233300.000000, \n",
      "10439972.000000, \n",
      "10646644.000000, \n",
      "10139916.000000, \n",
      "10346588.000000, \n",
      "10553260.000000, \n",
      "10759932.000000, \n",
      "10204004.000000, \n",
      "10410676.000000, \n",
      "10617348.000000, \n",
      "10824020.000000, \n",
      "10218892.000000, \n",
      "10425564.000000, \n",
      "10632236.000000, \n",
      "10838908.000000, \n",
      "10184580.000000, \n",
      "10391252.000000, \n",
      "10597924.000000, \n",
      "10804596.000000, \n",
      "10110368.000000, \n",
      "10317040.000000, \n",
      "10523712.000000, \n",
      "10730384.000000, \n",
      "10112388.000000, \n",
      "10319076.000000, \n",
      "10525764.000000, \n",
      "10732452.000000, \n",
      "9979740.000000, \n",
      "10186428.000000, \n",
      "10393116.000000, \n",
      "10599804.000000, \n",
      "9797892.000000, \n",
      "10004580.000000, \n",
      "10211268.000000, \n",
      "10417956.000000, \n",
      "9976844.000000, \n",
      "10183532.000000, \n",
      "10390220.000000, \n",
      "10596908.000000, \n",
      "10106596.000000, \n",
      "10313284.000000, \n",
      "10519972.000000, \n",
      "10726660.000000, \n",
      "10187148.000000, \n",
      "10393836.000000, \n",
      "10600524.000000, \n",
      "10807212.000000, \n",
      "10218500.000000, \n",
      "10425188.000000, \n",
      "10631876.000000, \n",
      "10838564.000000, \n",
      "10209552.000000, \n",
      "10416240.000000, \n",
      "10622928.000000, \n",
      "10829616.000000, \n",
      "10211524.000000, \n",
      "10418228.000000, \n",
      "10624932.000000, \n",
      "10831636.000000, \n",
      "\n",
      "--- Performance ---\n",
      "Kernel Time: 0.195776 ms\n",
      "Total FLOPs: 8.388608e+06\n",
      "GFLOPS/s:    42.847989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h> \n",
    "\n",
    "// No barrier needed for this simpler version\n",
    "\n",
    "constexpr int N = 4096; \n",
    "constexpr int BN = 32; \n",
    "constexpr int N_blocks = 1;\n",
    "constexpr int n_warps = 16;\n",
    "// These are not needed for this kernel\n",
    "// constexpr int n_producer_warps = 8;\n",
    "// constexpr int n_consumer_warps = n_warps - n_producer_warps;\n",
    "constexpr int block_size = n_warps*32; // 512 threads\n",
    "\n",
    "__global__ void matmul_tiled(float*A, float*B, float*C)\n",
    "{\n",
    "  // Single buffer for shared memory\n",
    "  __shared__ float As[BN*BN];\n",
    "  __shared__ float Bs[BN*BN];\n",
    "  \n",
    "  int t = threadIdx.x; // 0..511\n",
    "  \n",
    "  // Map 512 threads to a 16x32 grid\n",
    "  // Each thread will compute 2 elements of the C matrix\n",
    "  int thr_row = t / 32; // 0..15\n",
    "  int thr_col = t % 32; // 0..31\n",
    "  \n",
    "  // Registers to hold C results\n",
    "  float C_reg[2] = {0.0f, 0.0f};\n",
    "\n",
    "  // Each thread loads 2 floats (one float2) for As and 2 for Bs\n",
    "  // 512 threads * 2 floats/thread = 1024 floats (32*32)\n",
    "  int s_idx = t * 2;\n",
    "  int s_row = s_idx / BN;\n",
    "  int s_col = s_idx % BN;\n",
    "\n",
    "  for (int k = 0; k < N; k += BN)\n",
    "  {\n",
    "    // --- Load Tile from Global to Shared Memory ---\n",
    "    \n",
    "    // Load for As\n",
    "    // A is (BN x N), load A[s_row, k + s_col] & A[s_row, k + s_col + 1]\n",
    "    float* gA_ptr = &A[s_row * N + (k + s_col)];\n",
    "    float* sA_ptr = &As[s_row * BN + s_col];\n",
    "    *reinterpret_cast<float2*>(sA_ptr) = *reinterpret_cast<float2*>(gA_ptr);\n",
    "    \n",
    "    // Load for Bs\n",
    "    // B is (N x BN), load B[k + s_row, s_col] & B[k + s_row, s_col + 1]\n",
    "    float* gB_ptr = &B[(k + s_row) * BN + s_col];\n",
    "    float* sB_ptr = &Bs[s_row * BN + s_col];\n",
    "    *reinterpret_cast<float2*>(sB_ptr) = *reinterpret_cast<float2*>(gB_ptr);\n",
    "    \n",
    "    __syncthreads();\n",
    "    \n",
    "    // --- Compute Tile-level Matmul ---\n",
    "    // Each thread computes 2 elements\n",
    "    for (int dot_k = 0; dot_k < BN; dot_k++)\n",
    "    {\n",
    "      C_reg[0] += As[(thr_row +  0)*BN + dot_k] * Bs[dot_k*BN + thr_col];\n",
    "      C_reg[1] += As[(thr_row + 16)*BN + dot_k] * Bs[dot_k*BN + thr_col];\n",
    "    }\n",
    "    \n",
    "    __syncthreads();\n",
    "  }\n",
    "  \n",
    "  // --- Write results from Registers to Global ---\n",
    "  C[(thr_row +  0)*BN + thr_col] = C_reg[0];\n",
    "  C[(thr_row + 16)*BN + thr_col] = C_reg[1];\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  float *A_h, *A_d, *B_h, *B_d, *C_h, *C_d; \n",
    "  \n",
    "  size_t size_A = BN*N*sizeof(float); \n",
    "  size_t size_B = N*BN*sizeof(float); \n",
    "  size_t size_C = BN*BN*sizeof(float);\n",
    "  \n",
    "  cudaHostAlloc(&A_h, size_A, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&B_h, size_B, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&C_h, size_C, cudaHostAllocDefault);\n",
    "  \n",
    "  cudaMalloc(&A_d, size_A);\n",
    "  cudaMalloc(&B_d, size_B); \n",
    "  cudaMalloc(&C_d, size_C);\n",
    "  \n",
    "  for (int i = 0; i < BN*N; i++)\n",
    "  {\n",
    "    A_h[i] = (float) (i % 100) + 1.0f;\n",
    "    B_h[i] = (float) (i % 100) + 1.0f;\n",
    "  }\n",
    "  \n",
    "  cudaMemset(C_d, 0, size_C); \n",
    "\n",
    "  cudaMemcpy(A_d, A_h, size_A, cudaMemcpyHostToDevice);\n",
    "  cudaMemcpy(B_d, B_h, size_B, cudaMemcpyHostToDevice);\n",
    "  \n",
    "  cudaEvent_t start, stop;\n",
    "  float elapsedTime_ms;\n",
    "  cudaEventCreate(&start);\n",
    "  cudaEventCreate(&stop);\n",
    "\n",
    "  cudaEventRecord(start);\n",
    "  \n",
    "  // Call the new kernel\n",
    "  matmul_tiled<<<N_blocks, block_size>>>(A_d, B_d, C_d);\n",
    "  \n",
    "  cudaEventRecord(stop);\n",
    "  cudaEventSynchronize(stop);\n",
    "  cudaEventElapsedTime(&elapsedTime_ms, start, stop);\n",
    "  \n",
    "  cudaError_t err = cudaGetLastError();\n",
    "  if (err != cudaSuccess) {\n",
    "    printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
    "  }\n",
    "  \n",
    "  cudaMemcpy(C_h, C_d, size_C, cudaMemcpyDeviceToHost);\n",
    "  \n",
    "  printf(\"First 100 elements of C:\\n\");\n",
    "  for (int i = 0; i < 100; i++)\n",
    "  {\n",
    "    printf(\"%f, \\n\", C_h[i]);\n",
    "  }\n",
    "  \n",
    "  double total_flops = (double)BN * (double)BN * (2.0 * (double)N);\n",
    "  double gflops_per_sec = (total_flops / 1e9) / (elapsedTime_ms / 1000.0);\n",
    "\n",
    "  printf(\"\\n--- Performance ---\\n\");\n",
    "  printf(\"Kernel Time: %f ms\\n\", elapsedTime_ms);\n",
    "  printf(\"Total FLOPs: %e\\n\", total_flops);\n",
    "  printf(\"GFLOPS/s:    %f\\n\", gflops_per_sec);\n",
    "  \n",
    "  cudaEventDestroy(start);\n",
    "  cudaEventDestroy(stop);\n",
    "  \n",
    "  cudaFree(A_d);\n",
    "  cudaFree(B_d);\n",
    "  cudaFree(C_d);\n",
    "  cudaFreeHost(A_h);\n",
    "  cudaFreeHost(B_h);\n",
    "  cudaFreeHost(C_h);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8a7c9",
   "metadata": {},
   "source": [
    "So basically, the producer consumer overhead is completely fucked in our case. Time to think differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae17e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internal_venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
