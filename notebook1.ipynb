{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df97265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"/tmp/tmpgex17pkn\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter\n",
    "\n",
    "from nvcc4jupyter import set_defaults\n",
    "set_defaults(compiler_args=['-arch=sm_100a', '-Xptxas=-v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f7ade",
   "metadata": {},
   "source": [
    "Latency: if an instruction $I$, with latency $l$ takes in a tuple of input registers $(x_1,x_2,..x_n)$ and an output register $x$ then when we issue this at clock cycle $c$:\n",
    "- First, the instruction $I$ is fetched from instruction memory. it decodes it to understand what are input and output registers (register model here :)) Often, a register file has enough read ports such that for most instructions even if $x_1 = x_2 = ... x_n$ (all operands are equal) it is still possible to read them at once, (not always true).\n",
    "- Then, the values of the input registers are passed to the execution units, and crucially, at this point the input registers are now free to be read by any other instruction on the next clock cycle.\n",
    "ALL of the above happens at clock cycle $c$ \n",
    "\n",
    "At clock cycles $(c+1)$ to $c+l$ The ALU or whatnot is going to perform the operation of the instruction, (This is when the instruction is in flight, so a total of $l$ clock cycles is the latency) (indeed depending on the instruction, there may be overlap between compute and writeback stages and some concept called latch) [https://www.youtube.com/watch?v=yauQ7o1ZAAw] but nevertheless we move on. \n",
    "\n",
    "at clock cycle $c+l$ we do a writeback to $x$ via a write port to the register file. so if you want to use the register $x$ after this instruction was issued at clock cycle $c$, you can use it exactly at clock cycle $c+l+1$ onwards\n",
    "\n",
    "Throughput: The throughput of an instruction $I$ is essentially some time you need to wait before you can ISSUE any other instruction $I'$ given the operands or result registers that we issue $I'$ does not contain the output register held by the previous issue of $I$ (no data dependency), this is also sometimes called theoretical throughput. The reason I said \"some time\" instead of \"clock cycle\" was that for a scalar processor, the throughput of any instruction is one clock cycle. For a superscalar processor, one can issue many instructions per clock cycle.\n",
    "\n",
    "Memory Bandwith: The gb/s of data that can flow from the main RAM to the processor. one can use the clock speed of a processor to get comparisions between bandwidth rate and latency and throughput. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20804eae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
