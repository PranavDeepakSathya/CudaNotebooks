{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ef5101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"/tmp/tmps8b_gp8f\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter\n",
    "\n",
    "from nvcc4jupyter import set_defaults\n",
    "set_defaults(compiler_args='-arch=sm_100a -Xptxas=-v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802e45d",
   "metadata": {},
   "source": [
    "Indeed, the memory model is weak, that is, in paralell, if two threads are reading and writing the same peices of memory there is a data race and the behaviour is undefined. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e84d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  Before kernel execution  ====== \n",
      "A[0]: 1.000000, A[1]: 2.000000, A[2]: 3.000000, A[3]: 4.000000, \n",
      "====  After kernel execution  ====== \n",
      "A[0]: 1.000000, A[1]: 2.000000, A[2]: 3.000000, A[3]: 4.000000, \n"
     ]
    }
   ],
   "source": [
    "%%cuda \n",
    "\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "constexpr int N = 4;\n",
    "\n",
    "__global__ void kernel(float*A)\n",
    "{\n",
    "  \n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  float *A_d, *A_h; \n",
    "  size_t size = sizeof(float)*N; \n",
    "  \n",
    "  cudaHostAlloc(&A_h, size, cudaHostAllocDefault);\n",
    "  cudaMalloc(&A_d, size);\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    A_h[i] = (float)(i+1);\n",
    "  }\n",
    "  \n",
    "  cudaMemcpy(A_d, A_h, size, cudaMemcpyHostToDevice); \n",
    "  \n",
    "  printf(\"====  Before kernel execution  ====== \\n\");\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    printf(\"A[%d]: %f, \", i, A_h[i]);\n",
    "  }\n",
    "  printf(\"\\n\"); \n",
    "  printf(\"====  After kernel execution  ====== \\n\");\n",
    "  \n",
    "  kernel<<<1,32>>>(A_d);\n",
    "  \n",
    "  cudaDeviceSynchronize();\n",
    "  cudaMemcpy(A_h, A_d, size, cudaMemcpyDeviceToHost);\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    printf(\"A[%d]: %f, \", i, A_h[i]);\n",
    "  }\n",
    "  \n",
    "  cudaFree(A_d);\n",
    "  cudaFreeHost(A_h);\n",
    "  \n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe3119",
   "metadata": {},
   "source": [
    "So below, we have created a data race, each thread reads from the same index 0 and writes a different value to the same index of gmem. this is obviously an issue. so if this \n",
    "executing with some serialization, we would get A[0] = A[0] + 0 + 1 + 2 + 3, but since each thread is in paralell, the behaviour is undefined, here nothing is happening A[0] remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "567faa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  Before kernel execution  ====== \n",
      "A[0]: 1.000000, A[1]: 2.000000, A[2]: 3.000000, A[3]: 4.000000, \n",
      "====  After kernel execution  ====== \n",
      "A[0]: 1.000000, A[1]: 2.000000, A[2]: 3.000000, A[3]: 4.000000, \n"
     ]
    }
   ],
   "source": [
    "%%cuda \n",
    "\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "constexpr int N = 4;\n",
    "\n",
    "__global__ void race(float*A)\n",
    "{\n",
    "  uint t = threadIdx.x; \n",
    "  A[t/N] = A[t/N] + t;\n",
    "\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  float *A_d, *A_h; \n",
    "  size_t size = sizeof(float)*N; \n",
    "  \n",
    "  cudaHostAlloc(&A_h, size, cudaHostAllocDefault);\n",
    "  cudaMalloc(&A_d, size);\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    A_h[i] = (float)(i+1);\n",
    "  }\n",
    "  \n",
    "  cudaMemcpy(A_d, A_h, size, cudaMemcpyHostToDevice); \n",
    "  \n",
    "  printf(\"====  Before kernel execution  ====== \\n\");\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    printf(\"A[%d]: %f, \", i, A_h[i]);\n",
    "  }\n",
    "  printf(\"\\n\"); \n",
    "  printf(\"====  After kernel execution  ====== \\n\");\n",
    "  \n",
    "  race<<<1,N>>>(A_d);\n",
    "  \n",
    "  cudaDeviceSynchronize();\n",
    "  cudaMemcpy(A_h, A_d, size, cudaMemcpyDeviceToHost);\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    printf(\"A[%d]: %f, \", i, A_h[i]);\n",
    "  }\n",
    "  \n",
    "  cudaFree(A_d);\n",
    "  cudaFreeHost(A_h);\n",
    "  \n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbce85d",
   "metadata": {},
   "source": [
    "okay now we deploy 8 threads, we make the first 4 read the things, and then the next 4 write into the same things lets see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a710f356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  Before kernel execution  ====== \n",
      "A[0]: 1.000000, A[1]: 2.000000, A[2]: 3.000000, A[3]: 4.000000, \n",
      "====  After kernel execution  ====== \n",
      "A[0]: 0.100000, A[1]: 0.200000, A[2]: 0.300000, A[3]: 0.400000, \n"
     ]
    }
   ],
   "source": [
    "%%cuda \n",
    "\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "constexpr int N = 4;\n",
    "\n",
    "__global__ void race(float*A)\n",
    "{\n",
    "  uint t = threadIdx.x; \n",
    "  float r[4] = {0.1, 0.2, 0.3, 0.4};\n",
    "  float q[4] = {0.0};\n",
    "  \n",
    "  if (t < 4)\n",
    "  {\n",
    "    q[t] = A[t];\n",
    "  }\n",
    "  if (t > 3)\n",
    "  {\n",
    "    A[t-4] = r[t-4];\n",
    "  }\n",
    "\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  float *A_d, *A_h; \n",
    "  size_t size = sizeof(float)*N; \n",
    "  \n",
    "  cudaHostAlloc(&A_h, size, cudaHostAllocDefault);\n",
    "  cudaMalloc(&A_d, size);\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    A_h[i] = (float)(i+1);\n",
    "  }\n",
    "  \n",
    "  cudaMemcpy(A_d, A_h, size, cudaMemcpyHostToDevice); \n",
    "  \n",
    "  printf(\"====  Before kernel execution  ====== \\n\");\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    printf(\"A[%d]: %f, \", i, A_h[i]);\n",
    "  }\n",
    "  printf(\"\\n\"); \n",
    "  printf(\"====  After kernel execution  ====== \\n\");\n",
    "  \n",
    "  race<<<1,2*N>>>(A_d);\n",
    "  \n",
    "  cudaDeviceSynchronize();\n",
    "  cudaMemcpy(A_h, A_d, size, cudaMemcpyDeviceToHost);\n",
    "  for (int i = 0; i < N; i++)\n",
    "  {\n",
    "    printf(\"A[%d]: %f, \", i, A_h[i]);\n",
    "  }\n",
    "  \n",
    "  cudaFree(A_d);\n",
    "  cudaFreeHost(A_h);\n",
    "  \n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6f4dc",
   "metadata": {},
   "source": [
    "huh. No data race, so it means that the process is getting serialized. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
