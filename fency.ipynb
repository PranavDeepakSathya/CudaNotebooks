{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ef5101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"/tmp/tmpr0qgjj1d\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter\n",
    "\n",
    "from nvcc4jupyter import set_defaults\n",
    "set_defaults(compiler_args='-arch=sm_100a -Xptxas=-v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802e45d",
   "metadata": {},
   "source": [
    "Indeed, the memory model is weak, that is, in paralell, if two threads are reading and writing the same peices of memory there is a data race and the behaviour is undefined. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ae01af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Final X (if sequential): 538\n",
      "Actual Final X (data race result): 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda \n",
    "\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "\n",
    "__device__ int X = 10; \n",
    "\n",
    "__global__ void memory_race_race()\n",
    "{\n",
    "  uint t = threadIdx.x; \n",
    "\n",
    "  X = X + t + 1; \n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  int h_X; // Host copy\n",
    "  int expected_X = 10;\n",
    "  // Sum of (t + 1) for t=0 to 31 is (1+2+...+32) = 528.\n",
    "  // Expected final value is 10 + 528 = 538 (if sequential).\n",
    "  \n",
    "  memory_race_race<<<1, 32>>>();\n",
    "  cudaDeviceSynchronize();\n",
    "  \n",
    "  // Copy final result back to host\n",
    "// CORRECT\n",
    "  cudaMemcpy(&h_X, &X, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "  printf(\"Expected Final X (if sequential): %d\\n\", 538);\n",
    "  printf(\"Actual Final X (data race result): %d\\n\", h_X);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e84d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 0 Y: 0 A: 0 B: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda \n",
    "\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "\n",
    "__device__ int X = 1, Y=2, A = 5, B = 10; \n",
    "\n",
    "__device__ void writeXY()\n",
    "{\n",
    "    X = 10;\n",
    "    Y = 20;\n",
    "}\n",
    "\n",
    "__device__ void readXY()\n",
    "{\n",
    "    B = Y;\n",
    "    A = X;\n",
    "}\n",
    "\n",
    "__global__ void memory_race_race()\n",
    "{\n",
    "  uint t = threadIdx.x; \n",
    "  if (t == 0)\n",
    "  {\n",
    "    writeXY();\n",
    "  }\n",
    "  if (t == 1)\n",
    "  {\n",
    "    readXY();\n",
    "  }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  int h_X; // Host copy\n",
    "  int h_A;\n",
    "  int h_B;\n",
    "  int h_Y;\n",
    "  memory_race_race<<<1, 2>>>();\n",
    "  cudaDeviceSynchronize();\n",
    "  \n",
    "  // Copy final result back to host\n",
    "// CORRECT\n",
    "  cudaMemcpy(&h_X, &X, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_Y, &Y, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_A, &A, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_B, &B, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "  printf(\"X: %d Y: %d A: %d B: %d\\n\", h_X, h_Y, h_A, h_B);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56371d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 0 Y: 0 A: 0 B: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda \n",
    "\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "\n",
    "__device__ int X = 1, Y=2, A = 5, B = 10; \n",
    "\n",
    "__device__ void writeXY()\n",
    "{\n",
    "    X = 10;\n",
    "    __threadfence();\n",
    "    Y = 20;\n",
    "    __threadfence();\n",
    "}\n",
    "\n",
    "__device__ void readXY()\n",
    "{\n",
    "    A = X;\n",
    "    __threadfence();\n",
    "    B = Y;\n",
    "     __threadfence();\n",
    "    \n",
    "}\n",
    "\n",
    "__global__ void memory_race_race()\n",
    "{\n",
    "  uint t = threadIdx.x; \n",
    "  if (t == 0)\n",
    "  {\n",
    "    writeXY();\n",
    "  }\n",
    "  if (t == 1)\n",
    "  {\n",
    "    readXY();\n",
    "  }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  int h_X; // Host copy\n",
    "  int h_A;\n",
    "  int h_B;\n",
    "  int h_Y;\n",
    "  memory_race_race<<<1, 2>>>();\n",
    "  cudaDeviceSynchronize();\n",
    "  \n",
    "  // Copy final result back to host\n",
    "// CORRECT\n",
    "  cudaMemcpy(&h_X, &X, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_Y, &Y, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_A, &A, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_B, &B, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "  printf(\"X: %d Y: %d A: %d B: %d\\n\", h_X, h_Y, h_A, h_B);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0390d438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 10 \n",
      "X: 10 \n",
      "X: 0 Y: 0 A: 0 B: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda \n",
    "\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "\n",
    "__device__ int X = 1, Y=2, A = 5, B = 10; \n",
    "\n",
    "__device__ void writeXY()\n",
    "{\n",
    "    X = 10;\n",
    "\n",
    "    Y = 20;\n",
    "    \n",
    "}\n",
    "\n",
    "__device__ void readXY()\n",
    "{\n",
    "    A = X;\n",
    "\n",
    "    B = Y;\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "__global__ void memory_race_race()\n",
    "{\n",
    "  uint t = threadIdx.x; \n",
    "  if (t == 0)\n",
    "  {\n",
    "    writeXY();\n",
    "  }\n",
    "  \n",
    "  __syncthreads();\n",
    "  printf(\"X: %d \\n\", X);\n",
    "  if (t == 1)\n",
    "  {\n",
    "    readXY();\n",
    "  }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  int h_X; // Host copy\n",
    "  int h_A;\n",
    "  int h_B;\n",
    "  int h_Y;\n",
    "  memory_race_race<<<1, 2>>>();\n",
    "  cudaDeviceSynchronize();\n",
    "  \n",
    "  // Copy final result back to host\n",
    "// CORRECT\n",
    "  cudaMemcpy(&h_X, &X, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_Y, &Y, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_A, &A, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "  cudaMemcpy(&h_B, &B, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "  printf(\"X: %d Y: %d A: %d B: %d\\n\", h_X, h_Y, h_A, h_B);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29228a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 10 Y: 20 A: 10 B: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda \n",
    "\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda_runtime.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "// 1. Declare device variables without initialization\n",
    "__device__ int X, Y, A, B; \n",
    "\n",
    "__device__ void writeXY()\n",
    "{\n",
    "    X = 10;\n",
    "    Y = 20;\n",
    "}\n",
    "\n",
    "__device__ void readXY()\n",
    "{\n",
    "    B = Y; // Read Y's value into B\n",
    "    A = X; // Read X's value into A\n",
    "}\n",
    "\n",
    "// ðŸ’¥ Race Condition Kernel (Still a race on consistency!)\n",
    "__global__ void memory_race_race()\n",
    "{\n",
    "  uint t = threadIdx.x; \n",
    "  if (t == 0)\n",
    "  {\n",
    "    writeXY();\n",
    "  }\n",
    "  if (t == 1)\n",
    "  {\n",
    "    readXY();\n",
    "  }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    // Host-side initialization values\n",
    "    int host_X = 1, host_Y = 2;\n",
    "    int host_A = 5, host_B = 10;\n",
    "    \n",
    "    // 2. Copy initial values from host to device global variables\n",
    "    cudaMemcpyToSymbol(X, &host_X, sizeof(int));\n",
    "    cudaMemcpyToSymbol(Y, &host_Y, sizeof(int));\n",
    "    cudaMemcpyToSymbol(A, &host_A, sizeof(int));\n",
    "    cudaMemcpyToSymbol(B, &host_B, sizeof(int));\n",
    "\n",
    "    // 3. Launch the kernel\n",
    "    memory_race_race<<<1, 2>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // 4. Copy final results from device global variables to host\n",
    "    cudaMemcpyFromSymbol(&host_X, X, sizeof(int));\n",
    "    cudaMemcpyFromSymbol(&host_Y, Y, sizeof(int));\n",
    "    cudaMemcpyFromSymbol(&host_A, A, sizeof(int));\n",
    "    cudaMemcpyFromSymbol(&host_B, B, sizeof(int));\n",
    "\n",
    "    // The output will now be non-zero and non-deterministic (a race result).\n",
    "    printf(\"X: %d Y: %d A: %d B: %d\\n\", host_X, host_Y, host_A, host_B);\n",
    "  \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a7939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
