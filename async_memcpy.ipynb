{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc234fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"/tmp/tmp8o76x3e2\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter\n",
    "\n",
    "from nvcc4jupyter import set_defaults\n",
    "set_defaults(compiler_args='-arch=sm_100a -Xptxas=-v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01234347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "0.000000, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<cuda.h> \n",
    "#include<cuda_runtime.h> \n",
    "#include <cuda/barrier>\n",
    "#include <cooperative_groups.h>\n",
    "\n",
    "namespace cg = cooperative_groups;\n",
    "using barrier = cuda::barrier<cuda::thread_scope_block>;\n",
    "\n",
    "\n",
    "constexpr int N = 4096; \n",
    "constexpr int BN = 32; \n",
    "constexpr int N_blocks = 1;\n",
    "constexpr int block_size = BN*BN;\n",
    "/*\n",
    "#later, for ease of memcopy async, we will asume that both A and B are laid in \n",
    "# N*BN form, even though for a real matmul, it is indeed true that A would be BN*N and wed \n",
    "#need to take care of that, its just cause we can tell the fucking size and then the start addr\n",
    "#and just copy that block in from addr to addr + size when A is in N*BN form. \n",
    "*/\n",
    "\n",
    "__global__ void matmul(float*A, float*B, float*C)\n",
    "{\n",
    "  __shared__ float As[BN*BN];\n",
    "  __shared__ float Bs[BN*BN];\n",
    "  \n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  float *A_h, *A_d, *B_h, *B_d, *C_h, *C_d; \n",
    "  size_t size = N*BN*sizeof(float); \n",
    "  size_t size_C = BN*BN*sizeof(float);\n",
    "  cudaHostAlloc(&A_h, size, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&B_h, size, cudaHostAllocDefault);\n",
    "  cudaHostAlloc(&C_h, size_C, cudaHostAllocDefault);\n",
    "  cudaMalloc(&A_d, size);\n",
    "  cudaMalloc(&B_d, size); \n",
    "  cudaMalloc(&C_d, size_C);\n",
    "  for (int i = 0; i < BN*N; i++)\n",
    "  {\n",
    "    A_h[i] = (float) i / 10000.0; \n",
    "    B_h[i] = (float) i / 10000.0;\n",
    "  }\n",
    "  cudaMemcpy(A_d, A_h, size, cudaMemcpyHostToDevice);\n",
    "  cudaMemcpy(B_d, B_h, size, cudaMemcpyHostToDevice);\n",
    "  \n",
    "  matmul<<<N_blocks, block_size>>>(A_d, B_d, C_d);\n",
    "  \n",
    "  cudaDeviceSynchronize();\n",
    "  cudaMemcpy(C_h, C_d, size_C, cudaMemcpyDeviceToHost);\n",
    "  for (int i = 0; i < 100; i++)\n",
    "  {\n",
    "    printf(\"%f, \\n\", C_h[i]);\n",
    "  }\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b391e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
